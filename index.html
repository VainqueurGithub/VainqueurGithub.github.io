<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Computational Bioacoustics Research</title>
    <link href="https://fonts.googleapis.com/css2?family=Raleway:wght@300;700&display=swap" rel="stylesheet">
    <style>
        body {
            font-family: 'Raleway', sans-serif;
            margin: 0;
            padding: 0;
            background: #f4f4f4;
            color: #333;
        }

        header {
            background: #2C3E50;
            color: white;
            text-align: center;
            padding: 2rem 0;
        }

        .cv-btn {
            display: inline-block;
            padding: 10px 20px;
            margin-top: 10px;
            background: #2980B9;
            color: white;
            text-decoration: none;
            border-radius: 5px;
            font-weight: bold;
        }

            .cv-btn:hover {
                background: #3498DB;
            }

        .identity {
            text-align: center;
            padding: 1rem;
            background: #34495E;
            color: white;
        }

            .identity h2 {
                margin: 0;
                font-size: 1.5rem;
            }

            .identity p {
                margin: 0.3rem 0;
            }

        .container {
            width: 80%;
            margin: auto;
            padding: 2rem 0;
        }

        .section {
            background: white;
            padding: 2rem;
            margin-bottom: 1.5rem;
            border-radius: 10px;
            box-shadow: 0px 4px 8px rgba(0,0,0,0.1);
            text-align: center;
        }

        h1, h2 {
            text-align: center;
        }

        .profile-pic {
            width: 150px;
            height: 150px;
            border-radius: 50%;
            object-fit: cover;
            display: block;
            margin: 0 auto 1rem auto;
        }

        .research-img {
            width: 60%;
            margin: 1rem auto;
            display: block;
            border-radius: 10px;
            box-shadow: 0px 4px 8px rgba(0,0,0,0.1);
        }

        footer {
            text-align: center;
            padding: 1rem;
            background: #2C3E50;
            color: white;
        }
    </style>
</head>
<body>
    <header>
        <h1>Computational Bioacoustics Researcher</h1>
        <p>Exploring Soundscapes in Nature through AI & Machine Learning</p>
        <a href="CV.pdf" class="cv-btn" download>Download CV</a>
    </header>
    <div class="identity">
        <h2>KILINDO BULAMBO Vainqueur</h2>
        <p>Ecological Data Scientist | Bioacoustics Researcher</p>
        <p>Affiliation: Dian Fossey Gorilla Fund</p>
        <p>Email: vbulambo@gorillafund.org</p>
    </div>
    <div class="container">
        <div class="section">
            <img src="Vainqueur.JPG" alt="Profile Picture" class="profile-pic">
            <h2>About Me</h2>
            <p>🌍 Passionate about understanding the natural world through the lens of ecological data science and bioacoustics, I am dedicated to advancing wildlife research and conservation using cutting-edge technology. My primary focus lies in studying the vocalization patterns of gorillas and chimpanzees, with the aim of uncovering insights into their behavior, communication, and population dynamics.</p>
            <p>🔬 My work bridges biology and technology, leveraging machine learning and deep learning techniques to analyze soundscapes, identify species, and monitor biodiversity. From collecting field recordings in natural habitats to applying innovative data-driven approaches, I strive to make meaningful contributions to wildlife conservation and ecological research.</p>
            <h3>🔬 Achievements & Projects:</h3>
            <ul>
                <li>Collected and analyzed gorilla vocalization data from their natural environments (parks, and protected areas).</li>
                <li>Currently developing a deep learning model for gorilla detection and vocalization pattern analysis, with a friendly user interface.</li>
            </ul>
            <h3>💡 Skills & Interests:</h3>
            <ul>
                <li><strong>Bioacoustics:</strong> Field data collection and analysis of primate vocalizations.</li>
                <li><strong>Machine Learning:</strong> Developing and deploying models for sound pattern recognition.</li>
                <li><strong>Ecological Data Science:</strong> Harnessing data to monitor wildlife populations and biodiversity.</li>
                <li><strong>Technology in Conservation:</strong> Using AI to support sustainable solutions for wildlife and ecosystems.</li>
            </ul>
            <p>🌱 Currently aspiring to pursue a PhD in ecological data science, I aim to focus on the co-existence of gorillas and chimpanzees, using bioacoustics to understand their interactions and promote their protection.</p>
            <h3>📢 Let’s Connect:</h3>
            <p>I am eager to connect with professionals, researchers, and organizations in wildlife conservation, AI for good, and ecological innovation. Together, we can drive impactful solutions for our planet.</p>
        </div>
        <div class="section">
            <h2>Education</h2>
            <ul>
                <li><strong>M.Sc. in Artificial Intelligence</strong> - International University of Applied Science (Germany), 2024</li>
                <li><strong>B.Sc. in Computer Science</strong> - Université Lumière de Bujumbura (Burundi), 2020</li>
            </ul>
        </div>
        <div class="section">
            <h2>Awards</h2>
            <ul>
                <li>IU ALUMNI AWARD 2024, ARTIFICIAL INTELLIGENCE - International University of Applied Science (Germany), 2024</li>
                <li>Payne Fellow - Cornell lab of Ornithology, K. Lisa Yang Center for Bioacoustics Conservation, 2024</li>
            </ul>
        </div>
        <div class="section">
            <h2>Affiliation</h2>
            <p>Dian Fossey Gorilla Fund</p>
            <p>International University of Applied Science (Germany)</p>
            <p>K. Lisa Yang Center for Bioacoustics Conservation</p>
        </div>
        <div class="section">
            <h2>Research</h2>
            <p>My research focuses on the development of advanced sound event detection algorithms to analyze and classify primate vocalizations, particularly those of gorillas and chimpanzees. By leveraging deep learning and AI-driven techniques, I aim to create a robust and efficient system capable of detecting and differentiating vocalization patterns in real-time.</p>
            <p>Currently, I am developing a deep learning-based detector, inspired by YOLO, called YOHO (You Only Hear Once), which is designed specifically for sound event detection in ecological settings. This detector is trained on extensive datasets collected from various natural habitats, ensuring high accuracy in distinguishing between different primate calls.</p>
            <p>The detector features a user-friendly graphical interface that allows researchers and conservationists to upload and analyze audio recordings efficiently. Below are some images of the detector’s GUI in action:</p>
            <img src="Screenshot 2025-03-31 115142.png" alt="Detector Main Interface" class="research-img">
            <img src="Screenshot 2025-03-31 115557.png" alt="Detection events Interface" class="research-img">
            <img src="Figure_1.png" alt="Mapping Detection events Plot" class="research-img">
        </div>
        <div class="section">
            <h2>Publications</h2>
            <ul>
            </ul>
        </div>
        <div class="section">
            <h2>Contact</h2>
            <p>Email: vbulambo@gorillafund.org</p>
            <p>GitHub: <a href="https://github.com/VainqueurGithub/" target="_blank">github.com/VainqueurGithub</a></p>
            <p>LinkedIn: <a href="https://www.linkedin.com/in/msc-vainqueur-kilindo-1424ab1aa?utm_source=share&utm_campaign=share_via&utm_content=profile&utm_medium=android_app">LinkedIn</a></p>
        </div>
    </div>
    <footer>
        &copy; 2025 Computational Bioacoustics Researcher
    </footer>
</body>
</html>
